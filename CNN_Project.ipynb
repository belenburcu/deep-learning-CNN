{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                                                Burcu Belen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of Sensor Failures with CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Dataset\n",
    "\n",
    "Condition monitoring of hydraulic systems data: https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems\n",
    "\n",
    "The dataset addresses the condition assessment of a hydraulic test rig based on multi sensor data. Four fault types are superimposed with several severity grades impeding selective quantification.\n",
    "The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied. The data set contains raw process sensor data (i.e. without feature extraction) which are structured as matrices (tab-delimited) with the rows representing the cycles and the columns the data points within a cycle. The aim is to predict the state of the four hydraulic components according to the temperature sensors (TS1, TS2, TS3, TS4) measured with a frequency of 1 Hz (60 observations for each cycle). A model made with CNN in Keras will be used to analyze the classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains raw process sensor data (i.e. without feature extraction) which are structured as matrices (tab-delimited) with the rows representing the cycles and the columns the data points within a cycle. The sensors involved are:\n",
    "\n",
    "```\n",
    "      Sensor\tPhysical quantity\t\t\t\tUnit\t\tSampling rate\n",
    "      PS1\t\tPressure\t\t\t\t\t\tbar\t\t\t100 Hz\n",
    "      PS2\t\tPressure\t\t\t\t\t\tbar\t\t\t100 Hz\n",
    "      PS3\t\tPressure\t\t\t\t\t\tbar\t\t\t100 Hz\n",
    "      PS4\t\tPressure\t\t\t\t\t\tbar\t\t\t100 Hz\n",
    "      PS5\t\tPressure\t\t\t\t\t\tbar\t\t\t100 Hz\n",
    "      PS6\t\tPressure\t\t\t\t\t\tbar\t\t\t100 Hz\n",
    "      EPS1\t    Motor power\t\t\t\t\tW\t\t\t  100 Hz\n",
    "      FS1\t\tVolume flow\t\t\t\t\t l/min\t\t  10 Hz\n",
    "      FS2\t\tVolume flow\t\t\t\t\t l/min\t\t  10 Hz\n",
    "      TS1\t\tTemperature\t\t\t\t\t °C\t\t\t 1 Hz\n",
    "      TS2\t\tTemperature\t\t\t\t\t °C\t\t\t 1 Hz\n",
    "      TS3\t\tTemperature\t\t\t\t\t °C\t\t\t 1 Hz\n",
    "      TS4\t\tTemperature\t\t\t\t\t °C\t\t\t 1 Hz\n",
    "      VS1\t\tVibration\t\t\t\t\t\tmm/s\t\t  1 Hz\n",
    "      CE\t\tCooling efficiency (virtual)\t  %\t\t\t 1 Hz\n",
    "      CP\t\tCooling power (virtual)\t\t  kW\t\t\t 1 Hz\n",
    "      SE\t\tEfficiency factor\t\t\t\t %\t\t\t 1 Hz\n",
    "```\n",
    "\n",
    "The target condition values are cycle-wise annotated in ‘profile.txt‘ (tab-delimited). As before, the row number represents the cycle number. The columns are\n",
    "\n",
    "```\n",
    "\n",
    "1: Cooler condition / %:\n",
    "\t3: close to total failure\n",
    "\t20: reduced effifiency\n",
    "\t100: full efficiency\n",
    "\n",
    "2: Valve condition / %:\n",
    "\t100: optimal switching behavior\n",
    "\t90: small lag\n",
    "\t80: severe lag\n",
    "\t73: close to total failure\n",
    "\n",
    "3: Internal pump leakage:\n",
    "\t0: no leakage\n",
    "\t1: weak leakage\n",
    "\t2: severe leakage\n",
    "\n",
    "4: Hydraulic accumulator / bar:\n",
    "\t130: optimal pressure\n",
    "\t115: slightly reduced pressure\n",
    "\t100: severely reduced pressure\n",
    "\t90: close to total failure\n",
    "\n",
    "5: stable flag:\n",
    "\t0: conditions were stable\n",
    "\t1: static conditions might not have been reached yet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8820, 60)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.570</td>\n",
       "      <td>35.492</td>\n",
       "      <td>35.469</td>\n",
       "      <td>35.422</td>\n",
       "      <td>35.414</td>\n",
       "      <td>35.320</td>\n",
       "      <td>35.227</td>\n",
       "      <td>35.242</td>\n",
       "      <td>35.160</td>\n",
       "      <td>35.176</td>\n",
       "      <td>...</td>\n",
       "      <td>36.008</td>\n",
       "      <td>35.984</td>\n",
       "      <td>35.996</td>\n",
       "      <td>36.039</td>\n",
       "      <td>36.008</td>\n",
       "      <td>36.008</td>\n",
       "      <td>36.094</td>\n",
       "      <td>36.102</td>\n",
       "      <td>36.090</td>\n",
       "      <td>36.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.156</td>\n",
       "      <td>36.094</td>\n",
       "      <td>35.992</td>\n",
       "      <td>36.008</td>\n",
       "      <td>35.992</td>\n",
       "      <td>35.902</td>\n",
       "      <td>35.824</td>\n",
       "      <td>35.820</td>\n",
       "      <td>35.727</td>\n",
       "      <td>35.727</td>\n",
       "      <td>...</td>\n",
       "      <td>37.328</td>\n",
       "      <td>37.324</td>\n",
       "      <td>37.340</td>\n",
       "      <td>37.332</td>\n",
       "      <td>37.316</td>\n",
       "      <td>37.410</td>\n",
       "      <td>37.418</td>\n",
       "      <td>37.422</td>\n",
       "      <td>37.488</td>\n",
       "      <td>37.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.488</td>\n",
       "      <td>37.391</td>\n",
       "      <td>37.340</td>\n",
       "      <td>37.312</td>\n",
       "      <td>37.223</td>\n",
       "      <td>37.145</td>\n",
       "      <td>37.059</td>\n",
       "      <td>36.973</td>\n",
       "      <td>36.898</td>\n",
       "      <td>36.879</td>\n",
       "      <td>...</td>\n",
       "      <td>38.457</td>\n",
       "      <td>38.461</td>\n",
       "      <td>38.457</td>\n",
       "      <td>38.469</td>\n",
       "      <td>38.469</td>\n",
       "      <td>38.555</td>\n",
       "      <td>38.527</td>\n",
       "      <td>38.543</td>\n",
       "      <td>38.527</td>\n",
       "      <td>38.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.633</td>\n",
       "      <td>38.535</td>\n",
       "      <td>38.469</td>\n",
       "      <td>38.379</td>\n",
       "      <td>38.297</td>\n",
       "      <td>38.223</td>\n",
       "      <td>38.125</td>\n",
       "      <td>38.062</td>\n",
       "      <td>37.977</td>\n",
       "      <td>37.969</td>\n",
       "      <td>...</td>\n",
       "      <td>39.441</td>\n",
       "      <td>39.363</td>\n",
       "      <td>39.367</td>\n",
       "      <td>39.457</td>\n",
       "      <td>39.461</td>\n",
       "      <td>39.461</td>\n",
       "      <td>39.473</td>\n",
       "      <td>39.441</td>\n",
       "      <td>39.453</td>\n",
       "      <td>39.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.461</td>\n",
       "      <td>39.461</td>\n",
       "      <td>39.375</td>\n",
       "      <td>39.281</td>\n",
       "      <td>39.203</td>\n",
       "      <td>39.113</td>\n",
       "      <td>39.043</td>\n",
       "      <td>38.969</td>\n",
       "      <td>38.875</td>\n",
       "      <td>38.883</td>\n",
       "      <td>...</td>\n",
       "      <td>40.324</td>\n",
       "      <td>40.320</td>\n",
       "      <td>40.312</td>\n",
       "      <td>40.340</td>\n",
       "      <td>40.320</td>\n",
       "      <td>40.387</td>\n",
       "      <td>40.391</td>\n",
       "      <td>40.391</td>\n",
       "      <td>40.387</td>\n",
       "      <td>40.391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  35.570  35.492  35.469  35.422  35.414  35.320  35.227  35.242  35.160   \n",
       "1  36.156  36.094  35.992  36.008  35.992  35.902  35.824  35.820  35.727   \n",
       "2  37.488  37.391  37.340  37.312  37.223  37.145  37.059  36.973  36.898   \n",
       "3  38.633  38.535  38.469  38.379  38.297  38.223  38.125  38.062  37.977   \n",
       "4  39.461  39.461  39.375  39.281  39.203  39.113  39.043  38.969  38.875   \n",
       "\n",
       "       9   ...      50      51      52      53      54      55      56  \\\n",
       "0  35.176  ...  36.008  35.984  35.996  36.039  36.008  36.008  36.094   \n",
       "1  35.727  ...  37.328  37.324  37.340  37.332  37.316  37.410  37.418   \n",
       "2  36.879  ...  38.457  38.461  38.457  38.469  38.469  38.555  38.527   \n",
       "3  37.969  ...  39.441  39.363  39.367  39.457  39.461  39.461  39.473   \n",
       "4  38.883  ...  40.324  40.320  40.312  40.340  40.320  40.387  40.391   \n",
       "\n",
       "       57      58      59  \n",
       "0  36.102  36.090  36.152  \n",
       "1  37.422  37.488  37.477  \n",
       "2  38.543  38.527  38.621  \n",
       "3  39.441  39.453  39.461  \n",
       "4  40.391  40.387  40.391  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "label = pd.read_csv('profile.txt', sep='\\t', header=None)\n",
    "label.columns = ['Cooler','Valve','Pump','Accumulator','Flag']\n",
    "\n",
    "data = ['TS1.txt','TS2.txt','TS3.txt','TS4.txt']\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for txt in data:\n",
    "    read_df = pd.read_csv(txt, sep='\\t', header=None)\n",
    "    df = df.append(read_df)    \n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205, 60, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_index().values.reshape(-1,len(data),len(df.columns)).transpose(0,2,1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    741\n",
       "20     732\n",
       "3      732\n",
       "Name: Cooler, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = label.Cooler\n",
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 0, 20: 1, 100: 2}\n",
      "{0: 3, 1: 20, 2: 100}\n"
     ]
    }
   ],
   "source": [
    "# Label mapping\n",
    "diz_label, diz_reverse_label = {}, {}\n",
    "for i,lab in enumerate(label.unique()):\n",
    "    diz_label[lab] = i\n",
    "    diz_reverse_label[i] = lab\n",
    "\n",
    "print(diz_label)\n",
    "print(diz_reverse_label)\n",
    "label = label.map(diz_label)\n",
    "y = to_categorical(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, random_state = 42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1764, 60, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 60, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture features and non-obvious correlations of the series, a 1D CNN was used.\n",
    "The model was built to classify the state of the cooling component (Cooler condition) giving as input only the time series of the temperature in array format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "89/89 - 1s - loss: 0.2056 - accuracy: 0.9412 - val_loss: 0.0776 - val_accuracy: 0.9830 - 1s/epoch - 17ms/step\n",
      "Epoch 2/10\n",
      "89/89 - 1s - loss: 0.1237 - accuracy: 0.9773 - val_loss: 0.0586 - val_accuracy: 0.9802 - 873ms/epoch - 10ms/step\n",
      "Epoch 3/10\n",
      "89/89 - 1s - loss: 0.1033 - accuracy: 0.9780 - val_loss: 0.0840 - val_accuracy: 0.9802 - 856ms/epoch - 10ms/step\n",
      "Epoch 4/10\n",
      "89/89 - 1s - loss: 0.1197 - accuracy: 0.9709 - val_loss: 0.0876 - val_accuracy: 0.9745 - 782ms/epoch - 9ms/step\n",
      "Epoch 5/10\n",
      "89/89 - 1s - loss: 0.1078 - accuracy: 0.9766 - val_loss: 0.0670 - val_accuracy: 0.9802 - 821ms/epoch - 9ms/step\n",
      "Epoch 6/10\n",
      "89/89 - 1s - loss: 0.1032 - accuracy: 0.9773 - val_loss: 0.0581 - val_accuracy: 0.9887 - 828ms/epoch - 9ms/step\n",
      "Epoch 7/10\n",
      "89/89 - 1s - loss: 0.1049 - accuracy: 0.9766 - val_loss: 0.0690 - val_accuracy: 0.9802 - 806ms/epoch - 9ms/step\n",
      "Epoch 8/10\n",
      "89/89 - 1s - loss: 0.0885 - accuracy: 0.9780 - val_loss: 0.0726 - val_accuracy: 0.9830 - 824ms/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "89/89 - 1s - loss: 0.0966 - accuracy: 0.9773 - val_loss: 0.0769 - val_accuracy: 0.9830 - 829ms/epoch - 9ms/step\n",
      "Epoch 10/10\n",
      "89/89 - 1s - loss: 0.0875 - accuracy: 0.9766 - val_loss: 0.0694 - val_accuracy: 0.9830 - 816ms/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "num_sensors = 4\n",
    "TIME_PERIODS = 60\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "model_m = Sequential()\n",
    "model_m.add(Conv1D(100, 6, activation='relu', input_shape=(TIME_PERIODS, num_sensors)))\n",
    "model_m.add(Conv1D(100, 6, activation='relu'))\n",
    "model_m.add(MaxPooling1D(3))\n",
    "model_m.add(Conv1D(160, 6, activation='relu'))\n",
    "model_m.add(Conv1D(160, 6, activation='relu'))\n",
    "model_m.add(GlobalAveragePooling1D(name='G_A_P_1D'))\n",
    "model_m.add(Dropout(0.5))\n",
    "model_m.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model_m.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with 10 epoch reaches an accuracy of approximately 97% for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 0s - loss: 0.0415 - accuracy: 0.9932 - 66ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.041533395648002625, 0.9931972622871399]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_m.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = np.argmax(model_m.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.99      0.99       152\n",
      "          20       0.98      1.00      0.99       135\n",
      "         100       1.00      0.99      1.00       154\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([diz_reverse_label[np.argmax(label)] for label in y_test], \n",
    "                            [diz_reverse_label[label] for label in pred_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931972789115646"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score([diz_reverse_label[np.argmax(label)] for label in y_test], \n",
    "         [diz_reverse_label[label] for label in pred_test],\n",
    "         average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9934495329232171"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score([diz_reverse_label[np.argmax(label)] for label in y_test], \n",
    "         [diz_reverse_label[label] for label in pred_test],\n",
    "         average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931972789115646"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score([diz_reverse_label[np.argmax(label)] for label in y_test], \n",
    "         [diz_reverse_label[label] for label in pred_test],\n",
    "         average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930437144881566"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score([diz_reverse_label[np.argmax(label)] for label in y_test], \n",
    "         [diz_reverse_label[label] for label in pred_test],\n",
    "         average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
